{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f21bda5",
   "metadata": {},
   "source": [
    "# Run Test-Time Simulation with Single Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318bc61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import yaml \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009c63b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base reward scores with shape: (200, 200, 20)\n",
      "Loaded naft reward scores with shape: (200, 200, 20)\n"
     ]
    }
   ],
   "source": [
    "'---- Load the computed reward scores of each prompt, each image and each timestep ---'\n",
    "value_folder = 'values'\n",
    "diffusion_model = 'flux' # flux or sdxl\n",
    "reward_model = 'imr' # imr or pic or hps\n",
    "num_prompt = 200 # number of prompts to use\n",
    "num_image = 200 # number of images per prompt\n",
    "num_steps = 20 # number of diffusion inference timesteps\n",
    "\n",
    "reward_base_all = []  # shape (num_prompt, num_image, num_steps)\n",
    "reward_naft_all = [] # shape (num_prompt, num_image, num_steps)\n",
    "\n",
    "location_base = f'{value_folder}/{diffusion_model}_{reward_model}_val_base'\n",
    "for s in np.arange(num_steps):\n",
    "    file_name = f'p{num_prompt}_i{num_image}_s{s:02d}.yaml'\n",
    "    r_dict = yaml.safe_load(open(f'{location_base}/{file_name}')) \n",
    "    reward_one_step = np.stack([r_dict[k] for k in sorted(r_dict.keys())], axis=0) # shape (num_prompt, num_image)\n",
    "    reward_base_all.append(reward_one_step)\n",
    "reward_base_all = np.stack(reward_base_all, axis=-1) # shape (num_prompt, num_image, num_steps)\n",
    "print(f'Loaded base reward scores with shape: {reward_base_all.shape}')\n",
    "\n",
    "location_naft = f'{value_folder}/{diffusion_model}_{reward_model}_val_naft'\n",
    "for s in np.arange(num_steps):\n",
    "    file_name = f'p{num_prompt}_i{num_image}_s{s:02d}.yaml'\n",
    "    if not os.path.exists(f'{location_naft}/{file_name}'):\n",
    "        # some steps are not used for naft and we use base values instead, e.g. steps too high or too low\n",
    "        r_dict = yaml.safe_load(open(f'{location_base}/{file_name}')) \n",
    "    else:\n",
    "        r_dict = yaml.safe_load(open(f'{location_naft}/{file_name}')) \n",
    "    reward_one_step = np.stack([r_dict[k] for k in sorted(r_dict.keys())], axis=0) # shape (num_prompt, num_image)\n",
    "    reward_naft_all.append(reward_one_step)\n",
    "reward_naft_all = np.stack(reward_naft_all, axis=-1) # shape (num_prompt, num_image, num_steps)\n",
    "\n",
    "print(f'Loaded naft reward scores with shape: {reward_naft_all.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cbb5908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images used Best-of-N: 10\n",
      "Number of images used TTsnap: 38\n",
      "Averaged reward Best-of-N of all the prompts: 1.644121504655399\n",
      "Averaged reward TTsnap of all the prompts: 1.7378503455044119\n"
     ]
    }
   ],
   "source": [
    "'Compare TTSnap, TTSp and Best-of-N'\n",
    "from ttsnap_sim import *\n",
    "\n",
    "denoise_budget = 9.9 # TFlops\n",
    "verifier_budget = 1.2 # TFlops\n",
    "\n",
    "budget = 2000 \n",
    "iters = 40\n",
    "\n",
    "S = Simulation(x=denoise_budget, y=verifier_budget, max_step=num_steps)\n",
    "\n",
    "# Best-of-N\n",
    "n = int(budget / S.bon_cost())\n",
    "print('Number of images used Best-of-N:', n)\n",
    "r_bon, _ = S.bon_run(reward_base_all[:,:,-1], image_num_use=n, iters=iters)\n",
    "\n",
    "# TTsnap\n",
    "alphas = [0.4, 0.4, 0.5] # hyperparameters\n",
    "steps_use = [2, 6, 11] # hyperparameters\n",
    "n = int(budget / S.ttsp_cost(alpha_s=alphas, steps_use=steps_use))\n",
    "print('Number of images used TTsnap:', n)\n",
    "r_ttsp, _ = S.ttsp_run(reward_naft_all, image_num_use=n, alpha_s=alphas, steps_use=steps_use, iters=iters)\n",
    "\n",
    "print('Averaged reward Best-of-N of all the prompts:', r_bon)\n",
    "print('Averaged reward TTsnap of all the prompts:', r_ttsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c4276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1436b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reward",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

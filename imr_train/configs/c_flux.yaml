seed: 2000
log: 
  project: Debug_IMR
  name: try
  use_wandb: false
  save_checkpoint: true
  print_loss_every_iter: 1
  valid_every_epoch: 1
  plot_dir: outputs
  do_valid: false 
  checkpoint_dir: checkpoints_out
  save_checkpoint: False
  eval_start: false
time_config:
  step_targets: [14,13,12,11,10,9,8,7,6,5,4,3,2,1,0] # if range 0-19   [14,13,12,11,10,9,8,7,6,5,4,3,2,1,0]
data:
  train_gt_file: setup/reward_gt_flux_5k.yaml
  train_data_folder: data_flux_train 
  train_prompts_file: setup/dataset_prompts_train.json
  train_prompt_range: 10 # 2 for top 2 prompts, etc.
  train_num_per_prompt: 8 # number images per prompt 
  valid_gt_file: setup/reward_gt_flux_val_i88.yaml 
  valid_data_folder: data_flux_val  
  valid_prompts_file: setup/dataset_prompts_validation.json
  valid_prompt_range: 200
  valid_num_per_prompt: 80
train:
  base_model_path: checkpoints/ImageReward.pt
  batch_size: 100
  accum_steps: 1
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_eps: 1.0e-08
  lr: 3.0e-6
  min_lr_scale: 0.5
  max_grad_norm: 5.0
  scheduler_type: linear # or cosine or linear
  warmup_ratio: 0.0
  warmup_type: linear # or constant
  time_sample_strategy: 1 # 0: random each batch, 1: random inside batch, 2: fixed time_id
  vit_type: vit_normal # vit_timecond, vit_normal, vit_adaln
  curr_interval: 1 # number of epochs per curriculum step
  loss_mse_scale: 1.0
  loss_preference_scale: 0.0
  loss_preference_tau: 0.5
  base_model_time: 19 
  bn_before_loss: false 
  weight_decay: 0.01
